---
layout: post
title: "Hololens First Impressions"
date: 2021-03-13 17:58:00 -0000
categories: hololens mixed-reality
header-image: 7E789BF6-2576-4EBB-A739-6122E99F5D9C.jpeg
author: Michael Hemenway
---

When I watched the video below about the release of Microsoft's new Hololens 2, I was very excited to get my hands on one. 

<iframe width="560" height="315" src="https://www.youtube.com/embed/f0RTL_X7r_4" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>


Thanks to h.lab at Case Western Reserve University, our team is getting a chance to explore the Hololens and its participation in the emerging field of mixed reality. We will have much to say about Hololens as a participant in mixed reality, but here, I simply want to share some of my initial impressions of the Hololens experience.

## Materialities

The look and feel of the headset and even the case are very pleasing. The simplicity of design of the case and the headset remind me a bit of Apple's aesthetics for products like airpods. The overhead strap and the rear dial make it easy to have the lens sit nicely on the head and to easily cover the field of vision. The unit feels stable even with quick movements laterally. Most of the weight of the unit is in the back, which adds to the comfort. The visor adjuster on the front provides some variability in distance of lens from eyes, but this was the least comfortable part of the unit for me. Definitely need to experiment more with different angles of the visor and see how that impacts comfort, screen interaction, and access to the physical environment.

I am wearing the lens now as I type and it is interesting to type on a keyboard while looking at my computer screen and have the visual display of the lens active. I wish I could take a view capture of what I am seeing now to share here, but it does not seem possible to share my view easily with anyone else. Currently, I am watching my text as I type appear on one screen behind the lens display that is tilted with top farther from me than bottom because I activated the home menu with my head tilted downward. The opacity of the lens display allows me to see through it to the materialities directly behind it as long as the colors on the lens display are not too bold. 

> I have a instinct to call the home menu on the lens the home "screen." It very much functions like a touch screen in how I interact with it, but is it still a screen? What are the affordances of screen and how does that help us understand our possible relationships to this lens display? 

The home menu in the lens can be activated at any time by putting the inside (palm side) of either wrist into the visual field of the lens. I am curious why this action was chosen to activate the home menu? Does this indicate any assumptions about the bodies that might be engaging with the lens? Are there any accessibility challenges with this particular design for home menu activation? Once you have activated the lens with a microsoft account, then and only then does voice activation become available. Voice commands will certainly address some of the accessibility issues raised here. 

Of all of the views in the lens I have encountered so far, only the home menu does a good job of staying located within my field of view. When I move my head laterally or vertically, the home menu will follow, even if delayed a bit. The menu also attempts to maintain a limited depth range, such that when i walk toward the menu, it will let me get closer until a point and then it will begin to move forward to keep some minimum depth of field. The menu will also follow me backward at some maximal depth, though it does allow me to increase my distance to a degree. 

The tuning of this menu snapping to field of view needs some work though. Laterally, it is pretty responsive, keeping the whole menu visible as I nudge it left or right by moving my head. Yet, in the y-plane, as I tilt my head up or down, the menu gets erased until about two-thirds of the way up or down the menu without moving. At this 2/3 point, the menu begins to move but still only keeps the 1/3 visible until I reverse the movement a bit to uncover the erased two thirds. 

A few other brief notes about the particular materialities of the lens. The sound is rather nice in tone and quality for ambient speakers, but it is strange that others can hear these sounds without being able to see or participate in the views I see. 

This may have to do with how I calibrated the lens, but the depth of touch to interact with the display seems a bit off. I always have the sensation of pushing through the surface of the display with my finger rather than simply contacting the surface. Perhaps this is by design, to remind users that these surfaces will not push back on us like the glass of my ipad or the plastic of my keyboard.

## Extension 

My favorite feature of the lens so far is the extended touch tool. talk about reaching for distant ibjects and then washing with digital overlay. 
* Extending vision with cameras 
* extending touch in some ways - long reach
* reproducing basic interfaces like mouse and keyboard - is this a limitation of imagination or more about working with user dispositions?

## Mixed?

* on the one hand, the headset DOES allow me to use my hands/fingers as a mouse, so in a way this is mixing my physical materiality with the 3d digital objects in the view
* ? could we call the view of the lens as an horizon?
* Yet, when playing with 3d holograms, they did NOT interact with the physical world around me. e.g. elephant on pogo stick does not notice top of my daughters head
* Feels more like overlays of screens, hearkening back to old notions of mixed reality, than it does to a robust entanglement of material embodiments. 

## Allienation?

* insular view of world - nobody else sees what I see, where is interactivity?
* does the digital overlay/mixedness allienate me from myself or perhaps from the patient on the operating table?
